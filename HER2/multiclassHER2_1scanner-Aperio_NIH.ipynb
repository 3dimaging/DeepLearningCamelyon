{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HER2 One Scanner - Aperio NIH\n",
    "\n",
    "- 5-Fold (80/20) split, No Holdout Set\n",
    "- Truth = Categorical from Mean of 7 continuous scores \n",
    "- Epoch at automatic Stop when loss<.001 change \n",
    "- LeNet model, 10 layers, Dropout (0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/lib/python2.7/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from keras.callbacks import EarlyStopping\n",
    "from PIL import Image\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, Lambda\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc, classification_report\n",
    "import csv\n",
    "import cv2\n",
    "import scipy\n",
    "import os\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For single scanner\n",
    "BASE_PATH = '/home/diam/Desktop/HER2_data_categorical/Aperio_NIH/'\n",
    "#BASE PATH for working from home:\n",
    "#BASE_PATH = '/home/OSEL/Desktop/HER2_data_categorical/'\n",
    "#epochs = 10\n",
    "batch_size = 32\n",
    "num_classes = 3\n",
    "#epochs = 35"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data - Practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the version from Ravi's code:\n",
    "\n",
    "#FDA\n",
    "#X_FDA = []\n",
    "#idx_FDA = []\n",
    "#for index, image_filename in list(enumerate(BASE_PATH)):\n",
    "#\timg_file = cv2.imread(BASE_PATH + '/' + image_filename)\n",
    "#\tif img_file is not None:\n",
    "\t\t#img_file = smisc.imresize(arr = img_file, size = (600,760,3))\n",
    "#\t\timg_file = smisc.imresize(arr = img_file, size = (120,160,3))\t\t\n",
    "#\t\timg_arr = np.asarray(img_file)\n",
    "#\t\tX_FDA.append(img_arr)\n",
    "#\t\tidx_FDA.append(index)\n",
    "\n",
    "#X_FDA = np.asarray(X_FDA)\n",
    "#idx_FDA = np.asarray(idx_FDA)\n",
    "#random.seed(rs)\n",
    "#random_id = random.sample(idx_FDA, len(idx_FDA)/2)\n",
    "#random_FDA = []\n",
    "#for i in random_id:\n",
    "#\trandom_FDA.append(X_FDA[i])\n",
    "\n",
    "#random_FDA = np.asarray(random_FDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data - Real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(folder):\n",
    "    X = []\n",
    "    y = []\n",
    "    filenames = []\n",
    "\n",
    "    for hclass in os.listdir(folder):\n",
    "        if not hclass.startswith('.'):\n",
    "            if hclass in [\"0\"]:\n",
    "                label = 0\n",
    "            else: #label must be 1 or 2\n",
    "                if hclass in [\"1\"]:\n",
    "                    label = 1\n",
    "                else:\n",
    "                    label = 2\n",
    "            for image_filename in os.listdir(folder + hclass):\n",
    "                filename = folder + hclass + '/' + image_filename\n",
    "                img_file = cv2.imread(folder + hclass + '/' + image_filename)\n",
    "                \n",
    "                if img_file is not None:\n",
    "                    img_file = scipy.misc.imresize(arr=img_file, size=(120, 160, 3))\n",
    "                    img_arr = np.asarray(img_file)\n",
    "                    X.append(img_arr)\n",
    "                    y.append(label)\n",
    "                    filenames.append(filename)\n",
    "\n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y)\n",
    "    z = np.asarray(filenames)\n",
    "    return X,y,filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:20: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "241\n",
      "241\n",
      "241\n",
      "[[ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]]\n"
     ]
    }
   ],
   "source": [
    "X, y, z = get_data(BASE_PATH)\n",
    "\n",
    "\n",
    "#print(X)\n",
    "#print(y)\n",
    "#print(z)\n",
    "print(len(X))\n",
    "print(len(y))\n",
    "print(len(z))\n",
    "\n",
    "#INTEGER ENCODE\n",
    "#https://machinelearningmastery.com/how-to-one-hot-encode-sequence-data-in-python/\n",
    "encoder = LabelEncoder()\n",
    "y_cat = np_utils.to_categorical(encoder.fit_transform(y))\n",
    "print(y_cat)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#encoder = LabelEncoder()\n",
    "#encoder.fit(y)\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)\n",
    "\n",
    "#encoded_y_train = encoder.transform(y_train)\n",
    "#encoded_y_test = encoder.transform(y_test)\n",
    "\n",
    "#y_train = np_utils.to_categorical(encoded_y_train)\n",
    "#y_test = np_utils.to_categorical(encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Model with K-Fold X-Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "KFold(n_splits=5, random_state=5, shuffle=True)\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits = 5, random_state=5, shuffle=True)\n",
    "print(kf.get_n_splits(y))\n",
    "print(kf)\n",
    "\n",
    "\n",
    "#for train_index, test_index in kf.split(y):\n",
    "#    X_train, X_test = X[train_index], X[test_index]\n",
    "#    print(train_index, test_index)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold #1\n",
      "Train on 241 samples, validate on 49 samples\n",
      "Epoch 1/1000\n",
      "241/241 [==============================] - 2s 9ms/step - loss: 1.2005 - acc: 0.5187 - val_loss: 1.0059 - val_acc: 0.4694\n",
      "Epoch 2/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 1.0240 - acc: 0.5477 - val_loss: 0.9548 - val_acc: 0.4082\n",
      "Epoch 3/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 1.0413 - acc: 0.5062 - val_loss: 1.0083 - val_acc: 0.5306\n",
      "Epoch 4/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.8806 - acc: 0.5726 - val_loss: 0.9049 - val_acc: 0.5714\n",
      "Epoch 5/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.7851 - acc: 0.6680 - val_loss: 0.6530 - val_acc: 0.8163\n",
      "Epoch 6/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.8278 - acc: 0.6680 - val_loss: 0.7048 - val_acc: 0.6735\n",
      "Epoch 7/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.8295 - acc: 0.6598 - val_loss: 0.9497 - val_acc: 0.5714\n",
      "Epoch 8/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.6473 - acc: 0.7759 - val_loss: 1.5043 - val_acc: 0.4694\n",
      "Epoch 9/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.8319 - acc: 0.7344 - val_loss: 0.9338 - val_acc: 0.6327\n",
      "Epoch 10/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.6977 - acc: 0.7344 - val_loss: 0.5620 - val_acc: 0.8163\n",
      "Epoch 11/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.6577 - acc: 0.7635 - val_loss: 0.7094 - val_acc: 0.6939\n",
      "Epoch 12/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.6213 - acc: 0.7759 - val_loss: 0.4647 - val_acc: 0.8163\n",
      "Epoch 13/1000\n",
      "241/241 [==============================] - 0s 2ms/step - loss: 0.5872 - acc: 0.8050 - val_loss: 1.2169 - val_acc: 0.5510\n",
      "Epoch 14/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.6138 - acc: 0.7718 - val_loss: 0.4944 - val_acc: 0.8163\n",
      "Epoch 15/1000\n",
      "241/241 [==============================] - 0s 2ms/step - loss: 0.6764 - acc: 0.7676 - val_loss: 0.7672 - val_acc: 0.6735\n",
      "Epoch 16/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.5759 - acc: 0.8050 - val_loss: 0.4509 - val_acc: 0.8367\n",
      "Epoch 17/1000\n",
      "241/241 [==============================] - 0s 2ms/step - loss: 0.4979 - acc: 0.8257 - val_loss: 0.5433 - val_acc: 0.7551\n",
      "Epoch 18/1000\n",
      "241/241 [==============================] - 0s 2ms/step - loss: 0.6012 - acc: 0.7759 - val_loss: 0.8262 - val_acc: 0.6939\n",
      "Epoch 19/1000\n",
      "241/241 [==============================] - 0s 2ms/step - loss: 0.6307 - acc: 0.7759 - val_loss: 0.4257 - val_acc: 0.8163\n",
      "Epoch 20/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.6185 - acc: 0.7925 - val_loss: 0.5080 - val_acc: 0.7959\n",
      "Epoch 21/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.5301 - acc: 0.8133 - val_loss: 0.7163 - val_acc: 0.7143\n",
      "Epoch 22/1000\n",
      "241/241 [==============================] - 0s 2ms/step - loss: 0.5516 - acc: 0.8174 - val_loss: 0.4243 - val_acc: 0.8367\n",
      "Epoch 23/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.5779 - acc: 0.8008 - val_loss: 0.5023 - val_acc: 0.8163\n",
      "Epoch 24/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.4973 - acc: 0.8091 - val_loss: 0.4185 - val_acc: 0.8367\n",
      "Epoch 25/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.4989 - acc: 0.8340 - val_loss: 0.4261 - val_acc: 0.8367\n",
      "Epoch 26/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.5310 - acc: 0.8174 - val_loss: 0.3849 - val_acc: 0.8367\n",
      "Epoch 27/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.4767 - acc: 0.8216 - val_loss: 0.5176 - val_acc: 0.8163\n",
      "Epoch 28/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.4778 - acc: 0.8174 - val_loss: 0.4330 - val_acc: 0.8367\n",
      "Epoch 29/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.6645 - acc: 0.7759 - val_loss: 0.4433 - val_acc: 0.7755\n",
      "Epoch 30/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.5179 - acc: 0.8174 - val_loss: 0.3682 - val_acc: 0.8367\n",
      "Epoch 31/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.4462 - acc: 0.8299 - val_loss: 0.3982 - val_acc: 0.8367\n",
      "Epoch 32/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.4951 - acc: 0.8216 - val_loss: 0.7418 - val_acc: 0.7143\n",
      "Epoch 33/1000\n",
      "241/241 [==============================] - 0s 2ms/step - loss: 0.4427 - acc: 0.8382 - val_loss: 0.3570 - val_acc: 0.8367\n",
      "Epoch 34/1000\n",
      "241/241 [==============================] - 0s 2ms/step - loss: 0.4176 - acc: 0.8465 - val_loss: 0.5733 - val_acc: 0.7755\n",
      "Epoch 35/1000\n",
      "241/241 [==============================] - 0s 2ms/step - loss: 0.5229 - acc: 0.8299 - val_loss: 0.3462 - val_acc: 0.8571\n",
      "Epoch 36/1000\n",
      "241/241 [==============================] - 0s 2ms/step - loss: 0.4333 - acc: 0.8589 - val_loss: 0.3235 - val_acc: 0.8571\n",
      "Epoch 37/1000\n",
      "241/241 [==============================] - 0s 2ms/step - loss: 0.3643 - acc: 0.8714 - val_loss: 0.3080 - val_acc: 0.8571\n",
      "Epoch 38/1000\n",
      "241/241 [==============================] - 0s 2ms/step - loss: 0.6715 - acc: 0.7801 - val_loss: 0.3345 - val_acc: 0.8367\n",
      "Epoch 39/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.4286 - acc: 0.8382 - val_loss: 0.3204 - val_acc: 0.8571\n",
      "Epoch 40/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.3325 - acc: 0.8797 - val_loss: 0.3875 - val_acc: 0.8367\n",
      "Epoch 41/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.3866 - acc: 0.8631 - val_loss: 0.2810 - val_acc: 0.8571\n",
      "Epoch 42/1000\n",
      "241/241 [==============================] - 0s 2ms/step - loss: 0.4183 - acc: 0.8506 - val_loss: 0.3033 - val_acc: 0.8571\n",
      "Epoch 43/1000\n",
      "241/241 [==============================] - 0s 2ms/step - loss: 0.3706 - acc: 0.8506 - val_loss: 0.2960 - val_acc: 0.8571\n",
      "Epoch 44/1000\n",
      "241/241 [==============================] - 0s 2ms/step - loss: 0.5420 - acc: 0.7967 - val_loss: 0.3209 - val_acc: 0.8571\n",
      "Epoch 45/1000\n",
      "241/241 [==============================] - 0s 2ms/step - loss: 0.3466 - acc: 0.8465 - val_loss: 0.3009 - val_acc: 0.8571\n",
      "Epoch 46/1000\n",
      "241/241 [==============================] - 0s 2ms/step - loss: 0.3300 - acc: 0.8631 - val_loss: 0.3869 - val_acc: 0.8571\n",
      "Epoch 47/1000\n",
      "241/241 [==============================] - 0s 2ms/step - loss: 0.4905 - acc: 0.8216 - val_loss: 0.2805 - val_acc: 0.8571\n",
      "Epoch 48/1000\n",
      "241/241 [==============================] - 0s 2ms/step - loss: 0.3398 - acc: 0.8589 - val_loss: 0.3073 - val_acc: 0.8776\n",
      "Epoch 49/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.5201 - acc: 0.8091 - val_loss: 0.3067 - val_acc: 0.8571\n",
      "Epoch 50/1000\n",
      "241/241 [==============================] - 0s 2ms/step - loss: 0.3658 - acc: 0.8506 - val_loss: 0.2542 - val_acc: 0.8776\n",
      "Epoch 51/1000\n",
      "241/241 [==============================] - 0s 2ms/step - loss: 0.3011 - acc: 0.8714 - val_loss: 0.6756 - val_acc: 0.8571\n",
      "Epoch 52/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.3416 - acc: 0.8631 - val_loss: 0.2401 - val_acc: 0.8776\n",
      "Epoch 53/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.6203 - acc: 0.7801 - val_loss: 0.2737 - val_acc: 0.8776\n",
      "Epoch 54/1000\n",
      "241/241 [==============================] - 0s 2ms/step - loss: 0.3251 - acc: 0.8714 - val_loss: 0.2431 - val_acc: 0.8776\n",
      "Epoch 55/1000\n",
      "241/241 [==============================] - 0s 2ms/step - loss: 0.3124 - acc: 0.8631 - val_loss: 0.5098 - val_acc: 0.8571\n",
      "Epoch 56/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.4054 - acc: 0.8714 - val_loss: 0.2543 - val_acc: 0.8571\n",
      "Epoch 57/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.2977 - acc: 0.8672 - val_loss: 0.2807 - val_acc: 0.8571\n",
      "Epoch 58/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.3063 - acc: 0.8548 - val_loss: 0.2239 - val_acc: 0.8776\n",
      "Epoch 59/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.6034 - acc: 0.8299 - val_loss: 0.2640 - val_acc: 0.8571\n",
      "Epoch 60/1000\n",
      "241/241 [==============================] - 0s 2ms/step - loss: 0.3025 - acc: 0.8755 - val_loss: 0.2118 - val_acc: 0.8776\n",
      "Epoch 61/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.2850 - acc: 0.8921 - val_loss: 0.2614 - val_acc: 0.8571\n",
      "Epoch 62/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.2494 - acc: 0.8838 - val_loss: 0.2343 - val_acc: 0.8571\n",
      "Epoch 63/1000\n",
      "241/241 [==============================] - 0s 2ms/step - loss: 0.2841 - acc: 0.8672 - val_loss: 0.3282 - val_acc: 0.8571\n",
      "Epoch 64/1000\n",
      "241/241 [==============================] - 0s 2ms/step - loss: 0.3297 - acc: 0.8631 - val_loss: 0.3073 - val_acc: 0.8571\n",
      "Epoch 65/1000\n",
      "241/241 [==============================] - 0s 2ms/step - loss: 0.2553 - acc: 0.8797 - val_loss: 0.2098 - val_acc: 0.8571\n",
      "Epoch 66/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.3988 - acc: 0.8631 - val_loss: 0.1900 - val_acc: 0.8776\n",
      "Epoch 67/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.2348 - acc: 0.8921 - val_loss: 0.3464 - val_acc: 0.7959\n",
      "Epoch 68/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.2455 - acc: 0.8963 - val_loss: 0.2719 - val_acc: 0.8776\n",
      "Epoch 69/1000\n",
      "241/241 [==============================] - 0s 2ms/step - loss: 0.2390 - acc: 0.8880 - val_loss: 2.2662 - val_acc: 0.5714\n",
      "Epoch 70/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.5154 - acc: 0.8548 - val_loss: 0.2929 - val_acc: 0.8571\n",
      "Epoch 71/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.2465 - acc: 0.8797 - val_loss: 0.1676 - val_acc: 0.8776\n",
      "Epoch 72/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.2262 - acc: 0.8838 - val_loss: 2.8942 - val_acc: 0.6122\n",
      "Epoch 73/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.6819 - acc: 0.8382 - val_loss: 0.1859 - val_acc: 0.8776\n",
      "Epoch 74/1000\n",
      "241/241 [==============================] - 0s 2ms/step - loss: 0.2172 - acc: 0.8714 - val_loss: 0.1638 - val_acc: 0.8776\n",
      "Epoch 75/1000\n",
      "241/241 [==============================] - 0s 2ms/step - loss: 0.2333 - acc: 0.8755 - val_loss: 0.1573 - val_acc: 0.8776\n",
      "Epoch 76/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.2483 - acc: 0.8755 - val_loss: 0.7658 - val_acc: 0.7755\n",
      "Epoch 77/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.4406 - acc: 0.8589 - val_loss: 0.1763 - val_acc: 0.8776\n",
      "Epoch 78/1000\n",
      "241/241 [==============================] - 0s 2ms/step - loss: 0.2244 - acc: 0.8880 - val_loss: 0.1894 - val_acc: 0.8776\n",
      "Epoch 79/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.1973 - acc: 0.8921 - val_loss: 0.1585 - val_acc: 0.8776\n",
      "Epoch 80/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.2141 - acc: 0.9046 - val_loss: 0.1465 - val_acc: 0.8776\n",
      "Epoch 81/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.4551 - acc: 0.8174 - val_loss: 0.1648 - val_acc: 0.8776\n",
      "Epoch 82/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.2192 - acc: 0.8755 - val_loss: 0.2074 - val_acc: 0.8776\n",
      "Epoch 83/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.1785 - acc: 0.9004 - val_loss: 0.1703 - val_acc: 0.8776\n",
      "Epoch 84/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.2179 - acc: 0.8755 - val_loss: 0.1648 - val_acc: 0.8776\n",
      "Epoch 85/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.5330 - acc: 0.8423 - val_loss: 0.1997 - val_acc: 0.8776\n",
      "Epoch 86/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.2252 - acc: 0.8963 - val_loss: 0.1763 - val_acc: 0.8776\n",
      "Epoch 87/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.2075 - acc: 0.8963 - val_loss: 0.1329 - val_acc: 0.8776\n",
      "Epoch 88/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.1910 - acc: 0.8921 - val_loss: 0.2512 - val_acc: 0.8776\n",
      "Epoch 89/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.2462 - acc: 0.8963 - val_loss: 0.2511 - val_acc: 0.8571\n",
      "Epoch 90/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.2658 - acc: 0.8963 - val_loss: 0.1161 - val_acc: 0.9184\n",
      "Epoch 91/1000\n",
      "241/241 [==============================] - 0s 2ms/step - loss: 0.1779 - acc: 0.9212 - val_loss: 0.1698 - val_acc: 0.9388\n",
      "Epoch 92/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.1548 - acc: 0.9212 - val_loss: 0.0812 - val_acc: 0.9796\n",
      "Epoch 93/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.1580 - acc: 0.9087 - val_loss: 0.1099 - val_acc: 0.9592\n",
      "Epoch 94/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.7523 - acc: 0.8257 - val_loss: 0.1282 - val_acc: 0.9388\n",
      "Epoch 95/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.1691 - acc: 0.9336 - val_loss: 0.1074 - val_acc: 0.9592\n",
      "Epoch 96/1000\n",
      "241/241 [==============================] - 0s 2ms/step - loss: 0.1560 - acc: 0.9253 - val_loss: 0.0960 - val_acc: 0.9796\n",
      "Epoch 97/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.1774 - acc: 0.9087 - val_loss: 0.1167 - val_acc: 0.9388\n",
      "Epoch 98/1000\n",
      "241/241 [==============================] - 0s 2ms/step - loss: 0.1656 - acc: 0.9004 - val_loss: 0.0973 - val_acc: 0.9592\n",
      "Epoch 99/1000\n",
      "241/241 [==============================] - 0s 2ms/step - loss: 0.4401 - acc: 0.8465 - val_loss: 0.1682 - val_acc: 0.8980\n",
      "Epoch 100/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.2015 - acc: 0.9253 - val_loss: 0.0980 - val_acc: 0.9388\n",
      "Epoch 101/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.1350 - acc: 0.9253 - val_loss: 0.1206 - val_acc: 1.0000\n",
      "Epoch 102/1000\n",
      "241/241 [==============================] - 0s 2ms/step - loss: 0.1870 - acc: 0.8755 - val_loss: 0.0856 - val_acc: 0.9592\n",
      "Epoch 103/1000\n",
      "241/241 [==============================] - 0s 2ms/step - loss: 0.1193 - acc: 0.9378 - val_loss: 0.0533 - val_acc: 1.0000\n",
      "Epoch 104/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.6666 - acc: 0.8589 - val_loss: 0.1089 - val_acc: 0.9388\n",
      "Epoch 105/1000\n",
      "241/241 [==============================] - 0s 2ms/step - loss: 0.1542 - acc: 0.9212 - val_loss: 0.1306 - val_acc: 0.9184\n",
      "Epoch 106/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.1557 - acc: 0.9295 - val_loss: 0.0674 - val_acc: 0.9796\n",
      "Epoch 107/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.1094 - acc: 0.9585 - val_loss: 0.0478 - val_acc: 1.0000\n",
      "Epoch 108/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.2424 - acc: 0.9046 - val_loss: 0.1150 - val_acc: 1.0000\n",
      "Epoch 109/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.2234 - acc: 0.9212 - val_loss: 0.0798 - val_acc: 0.9592\n",
      "Epoch 110/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.1250 - acc: 0.9419 - val_loss: 0.0479 - val_acc: 1.0000\n",
      "Epoch 111/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.1386 - acc: 0.9253 - val_loss: 0.1390 - val_acc: 0.9388\n",
      "Epoch 112/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.1257 - acc: 0.9295 - val_loss: 0.2177 - val_acc: 0.8776\n",
      "Epoch 113/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.3697 - acc: 0.8755 - val_loss: 0.0917 - val_acc: 0.9388\n",
      "Epoch 114/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.1473 - acc: 0.9295 - val_loss: 0.0605 - val_acc: 1.0000\n",
      "Epoch 115/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.1045 - acc: 0.9502 - val_loss: 0.0542 - val_acc: 1.0000\n",
      "Epoch 116/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.1140 - acc: 0.9461 - val_loss: 0.0495 - val_acc: 1.0000\n",
      "Epoch 117/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.1233 - acc: 0.9502 - val_loss: 0.0874 - val_acc: 0.9388\n",
      "Epoch 118/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.1209 - acc: 0.9461 - val_loss: 0.9052 - val_acc: 0.8163\n",
      "Epoch 119/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.7064 - acc: 0.8257 - val_loss: 0.0879 - val_acc: 0.9388\n",
      "Epoch 120/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.1310 - acc: 0.9336 - val_loss: 0.0744 - val_acc: 0.9796\n",
      "Epoch 121/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "241/241 [==============================] - 0s 1ms/step - loss: 0.1270 - acc: 0.9461 - val_loss: 0.0452 - val_acc: 1.0000\n",
      "Epoch 122/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0681 - acc: 0.9876 - val_loss: 0.0339 - val_acc: 1.0000\n",
      "Epoch 123/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.1345 - acc: 0.9378 - val_loss: 0.0422 - val_acc: 1.0000\n",
      "Epoch 124/1000\n",
      "241/241 [==============================] - 0s 2ms/step - loss: 0.5164 - acc: 0.8382 - val_loss: 0.0978 - val_acc: 0.9796\n",
      "Epoch 125/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.1247 - acc: 0.9461 - val_loss: 0.0558 - val_acc: 1.0000\n",
      "Epoch 126/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0893 - acc: 0.9710 - val_loss: 0.0430 - val_acc: 1.0000\n",
      "Epoch 127/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0741 - acc: 0.9751 - val_loss: 0.0330 - val_acc: 1.0000\n",
      "Epoch 128/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.1811 - acc: 0.9378 - val_loss: 0.0429 - val_acc: 1.0000\n",
      "Epoch 129/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0999 - acc: 0.9585 - val_loss: 0.0382 - val_acc: 1.0000\n",
      "Epoch 130/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.1157 - acc: 0.9502 - val_loss: 0.0408 - val_acc: 1.0000\n",
      "Epoch 131/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.4407 - acc: 0.9004 - val_loss: 0.0694 - val_acc: 1.0000\n",
      "Epoch 132/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.1370 - acc: 0.9419 - val_loss: 0.0439 - val_acc: 1.0000\n",
      "Epoch 133/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0734 - acc: 0.9751 - val_loss: 0.0251 - val_acc: 1.0000\n",
      "Epoch 134/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0826 - acc: 0.9668 - val_loss: 0.0227 - val_acc: 1.0000\n",
      "Epoch 135/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0996 - acc: 0.9544 - val_loss: 0.0194 - val_acc: 1.0000\n",
      "Epoch 136/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.1061 - acc: 0.9502 - val_loss: 0.0180 - val_acc: 1.0000\n",
      "Epoch 137/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0838 - acc: 0.9668 - val_loss: 0.0225 - val_acc: 1.0000\n",
      "Epoch 138/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.5038 - acc: 0.9170 - val_loss: 0.0905 - val_acc: 1.0000\n",
      "Epoch 139/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.1811 - acc: 0.9253 - val_loss: 0.0526 - val_acc: 1.0000\n",
      "Epoch 140/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0783 - acc: 0.9668 - val_loss: 0.0318 - val_acc: 1.0000\n",
      "Epoch 141/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0612 - acc: 0.9751 - val_loss: 0.0079 - val_acc: 1.0000\n",
      "Epoch 142/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0680 - acc: 0.9751 - val_loss: 0.0052 - val_acc: 1.0000\n",
      "Epoch 143/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.4456 - acc: 0.8921 - val_loss: 0.0376 - val_acc: 1.0000\n",
      "Epoch 144/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.1152 - acc: 0.9461 - val_loss: 0.0262 - val_acc: 1.0000\n",
      "Epoch 145/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0617 - acc: 0.9751 - val_loss: 0.0195 - val_acc: 1.0000\n",
      "Epoch 146/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0937 - acc: 0.9378 - val_loss: 0.0183 - val_acc: 1.0000\n",
      "Epoch 147/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0740 - acc: 0.9627 - val_loss: 0.0206 - val_acc: 1.0000\n",
      "Epoch 148/1000\n",
      "241/241 [==============================] - 0s 2ms/step - loss: 0.1471 - acc: 0.9378 - val_loss: 0.0202 - val_acc: 1.0000\n",
      "Epoch 149/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0989 - acc: 0.9627 - val_loss: 0.0223 - val_acc: 1.0000\n",
      "Epoch 150/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0701 - acc: 0.9544 - val_loss: 0.0076 - val_acc: 1.0000\n",
      "Epoch 151/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0689 - acc: 0.9668 - val_loss: 0.0069 - val_acc: 1.0000\n",
      "Epoch 152/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0661 - acc: 0.9710 - val_loss: 0.0087 - val_acc: 1.0000\n",
      "Epoch 153/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0446 - acc: 0.9876 - val_loss: 1.3085 - val_acc: 0.8571\n",
      "Epoch 154/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.2485 - acc: 0.9253 - val_loss: 0.0215 - val_acc: 1.0000\n",
      "Epoch 155/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0740 - acc: 0.9585 - val_loss: 0.0197 - val_acc: 1.0000\n",
      "Epoch 156/1000\n",
      "241/241 [==============================] - 0s 2ms/step - loss: 0.0689 - acc: 0.9751 - val_loss: 0.0089 - val_acc: 1.0000\n",
      "Epoch 157/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.9127 - acc: 0.8797 - val_loss: 0.0272 - val_acc: 1.0000\n",
      "Epoch 158/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.1072 - acc: 0.9419 - val_loss: 0.0257 - val_acc: 1.0000\n",
      "Epoch 159/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0888 - acc: 0.9544 - val_loss: 0.0105 - val_acc: 1.0000\n",
      "Epoch 160/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0688 - acc: 0.9710 - val_loss: 0.0080 - val_acc: 1.0000\n",
      "Epoch 161/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0751 - acc: 0.9668 - val_loss: 0.0059 - val_acc: 1.0000\n",
      "Epoch 162/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0771 - acc: 0.9502 - val_loss: 0.0747 - val_acc: 0.9592\n",
      "Epoch 163/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0560 - acc: 0.9751 - val_loss: 0.0042 - val_acc: 1.0000\n",
      "Epoch 164/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0496 - acc: 0.9834 - val_loss: 0.0119 - val_acc: 1.0000\n",
      "Epoch 165/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.4873 - acc: 0.8921 - val_loss: 0.0242 - val_acc: 1.0000\n",
      "Epoch 166/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0776 - acc: 0.9751 - val_loss: 0.0161 - val_acc: 1.0000\n",
      "Epoch 167/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0733 - acc: 0.9751 - val_loss: 0.0066 - val_acc: 1.0000\n",
      "Epoch 168/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0529 - acc: 0.9751 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 169/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0366 - acc: 0.9793 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 170/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.4349 - acc: 0.8921 - val_loss: 0.0096 - val_acc: 1.0000\n",
      "Epoch 171/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0966 - acc: 0.9502 - val_loss: 0.0104 - val_acc: 1.0000\n",
      "Epoch 172/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0611 - acc: 0.9834 - val_loss: 0.0056 - val_acc: 1.0000\n",
      "Epoch 173/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.1017 - acc: 0.9461 - val_loss: 0.0106 - val_acc: 1.0000\n",
      "Epoch 174/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0771 - acc: 0.9502 - val_loss: 0.4751 - val_acc: 0.8776\n",
      "Epoch 175/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.2630 - acc: 0.9004 - val_loss: 0.0155 - val_acc: 1.0000\n",
      "Epoch 176/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0674 - acc: 0.9751 - val_loss: 0.0058 - val_acc: 1.0000\n",
      "Epoch 177/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0709 - acc: 0.9668 - val_loss: 0.0053 - val_acc: 1.0000\n",
      "Epoch 178/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0791 - acc: 0.9544 - val_loss: 0.0081 - val_acc: 1.0000\n",
      "Epoch 179/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0629 - acc: 0.9710 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 180/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.5664 - acc: 0.9253 - val_loss: 0.0177 - val_acc: 1.0000\n",
      "Epoch 181/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0825 - acc: 0.9627 - val_loss: 0.0078 - val_acc: 1.0000\n",
      "Epoch 182/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0297 - acc: 0.9917 - val_loss: 0.1046 - val_acc: 0.9388\n",
      "Epoch 183/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0938 - acc: 0.9627 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 184/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0693 - acc: 0.9627 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 185/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0666 - acc: 0.9793 - val_loss: 0.0038 - val_acc: 1.0000\n",
      "Epoch 186/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0492 - acc: 0.9834 - val_loss: 9.7847e-04 - val_acc: 1.0000\n",
      "Epoch 187/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.3322 - acc: 0.9461 - val_loss: 0.8660 - val_acc: 0.7959\n",
      "Epoch 188/1000\n",
      "241/241 [==============================] - 0s 2ms/step - loss: 0.1763 - acc: 0.9585 - val_loss: 0.0061 - val_acc: 1.0000\n",
      "Epoch 189/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0881 - acc: 0.9585 - val_loss: 0.0046 - val_acc: 1.0000\n",
      "Epoch 190/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0877 - acc: 0.9668 - val_loss: 0.0421 - val_acc: 0.9796\n",
      "Epoch 191/1000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0696 - acc: 0.9627 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 192/1000\n",
      " 32/241 [==>...........................] - ETA: 0s - loss: 0.1118 - acc: 0.9375"
     ]
    }
   ],
   "source": [
    "\n",
    "oos_y = []\n",
    "oos_pred = []\n",
    "fold = 0\n",
    "\n",
    "\n",
    "for train, test in kf.split(y_cat):\n",
    "    fold+=1\n",
    "    print(\"fold #{}\".format(fold))\n",
    "        \n",
    "    X_train = X[train]\n",
    "    y_train = y_cat[train]\n",
    "    X_test = X[test]\n",
    "    y_test = y_cat[test]\n",
    "    \n",
    "    #encoder = LabelEncoder()\n",
    "    #encoder.fit(y_test)\n",
    "    #y_train = np_utils.to_categorical(encoder.transform(y_train))\n",
    "    #y_test = np_utils.to_categorical(encoder.transform(y_test))\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Lambda(lambda x: x * 1./255., input_shape=(120, 160, 3), output_shape=(120, 160, 3)))\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=(120, 160, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.7))\n",
    "    model.add(Dense(3))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                optimizer='rmsprop',\n",
    "                metrics=['accuracy'])\n",
    "    \n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=25, verbose=1, mode='auto')\n",
    "    \n",
    "    model.fit(\n",
    "            X,\n",
    "            y_cat,\n",
    "            validation_data=(X_test,y_test),\n",
    "            callbacks=[monitor],\n",
    "            shuffle=True,\n",
    "            batch_size=batch_size,\n",
    "            verbose=1,\n",
    "            epochs=1000)\n",
    "        \n",
    "    pred = model.predict(X_test)\n",
    "        \n",
    "    oos_y.append(y_test)\n",
    "    pred = np.argmax(pred,axis=1)\n",
    "    oos_pred.append(pred)\n",
    "    \n",
    "        #measure the fold's accuracy\n",
    "    y_compare = np.argmax(y_test,axis=1) #for accuracy calculation\n",
    "    score = metrics.accuracy_score(y_compare, pred)\n",
    "    print(\"Fold Score (accuracy): {}\".format(score))\n",
    "    print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
