{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HER2 One Scanner - Hamamatsu2\n",
    "\n",
    "- 5-Fold (80/20) split, No Holdout Set\n",
    "- Truth = Categorical from Mean of 7 continuous scores \n",
    "- Epoch at automatic Stop when loss<.001 change \n",
    "- LeNet model, 10 layers, Dropout (0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from keras.callbacks import EarlyStopping\n",
    "from PIL import Image\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, Lambda\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc, classification_report\n",
    "import csv\n",
    "import cv2\n",
    "import scipy\n",
    "import os\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For single scanner\n",
    "BASE_PATH = '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/'\n",
    "#BASE PATH for working from home:\n",
    "#BASE_PATH = '/home/OSEL/Desktop/HER2_data_categorical/'\n",
    "#epochs = 10\n",
    "batch_size = 32\n",
    "num_classes = 3\n",
    "#epochs = 35"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data - Practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the version from Ravi's code:\n",
    "\n",
    "#FDA\n",
    "#X_FDA = []\n",
    "#idx_FDA = []\n",
    "#for index, image_filename in list(enumerate(BASE_PATH)):\n",
    "#\timg_file = cv2.imread(BASE_PATH + '/' + image_filename)\n",
    "#\tif img_file is not None:\n",
    "\t\t#img_file = smisc.imresize(arr = img_file, size = (600,760,3))\n",
    "#\t\timg_file = smisc.imresize(arr = img_file, size = (120,160,3))\t\t\n",
    "#\t\timg_arr = np.asarray(img_file)\n",
    "#\t\tX_FDA.append(img_arr)\n",
    "#\t\tidx_FDA.append(index)\n",
    "\n",
    "#X_FDA = np.asarray(X_FDA)\n",
    "#idx_FDA = np.asarray(idx_FDA)\n",
    "#random.seed(rs)\n",
    "#random_id = random.sample(idx_FDA, len(idx_FDA)/2)\n",
    "#random_FDA = []\n",
    "#for i in random_id:\n",
    "#\trandom_FDA.append(X_FDA[i])\n",
    "\n",
    "#random_FDA = np.asarray(random_FDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data - Real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/s06-8072-12600-25654H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/s06-8180-43448-12282H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/s05-10520-11042-8038H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/S05-1450-2505-13698H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/s06-5870-38338-10548H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/s06-2733-30431-32024H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/S06-246B-15645-13393H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/s06-8304-51447-9570H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/8811-22044,13754H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/S04-6537-19553-22436H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/5578-6H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/9981-8612,1379H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/s06-8304-63076-17460H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/S04-3584-15435-17232H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/9981-8776,12259H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/S04-6646-B-12629-8173H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/S05-1575-C7-14342-34616H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/s06-6874-15966-8309H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/S03-7771-33183-21230H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/s06-9179-a-16278-23775H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/S04-6577-13144-14557H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/S06-848-A-21343-3219H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/S03-3203-12793-7626H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/S03-9040-11925-18860H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/S05-1147-14631-10906H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/S03-9040-9551-18016H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/S03-7771-41810-30531H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/S04-3584-13315-15947H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/4816-8176,8561H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/s06-2790-13713-8570H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/s06-2790-11799-9071H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/s05-1475-4094-4270H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/s06-870-A1-4311-11774H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/s06-9179-a-15922-25041H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/S05-1147-2879-4097H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/s05-1475-2242-8967H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/S06-6377-6556-8769H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/S04-7685-B4-31214-15448H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/S04-8172-36570-40295H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/s06-8072-57530-29741H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/S03-9040-9255-16857H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/S06-7323-a5-38852-20028H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/8701-D-54921-8047H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/s06-2733-28079-27561H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/s06-4441-15615-5054H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/S04-8172-40671-42808H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/s06-2790-8016-10024H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/s06-8072-61067-29137H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/S04-3584-15769-25307H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/S06-246B-6969-16207H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/9981-8970,10677H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/5578-2H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/8811-27604,15487H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/s05-10520-11590-25579H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/S05-1450-7858-10493H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/s06-8072-61449-18169H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/s06-9179-a-16478-25792H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/S06-848-A-22282-6498H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/S06-7323-a5-23855-21815H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/S03-7771-27503-31152H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/s06-8072-11011-11575H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/s06-8072-6257-31543H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/S06-7323-a5-13901-15387H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/S05-1575-C7-12008-30326H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/8701-D-56699-23957H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/S04-6646-B-12488-3006H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/S06-246B-5542-14347H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/S06-106-2620-869H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/S06-6377-18584-23026H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/s06-8341-56880-24715H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/7692-4H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/s05-1475-13602-13155H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/s06-4441-24193-25166H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/s06-2790-7635-5852H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/s06-9179-a-17163-25163H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/8701-D-47906-21873H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/S04-6537-21909-7927H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/s06-2790-14402-3436H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/S04-6544-5342-12925H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/6670-978,2259H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/s06-2733-23830-24073H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/S05-1147-15152-10139H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/S06-246B-15724-14492H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/S05-1450-3745-16838H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/S06-6377-5575-14668H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/6501-5H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/S06-6377-24389-21686H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/s06-8341-60670-28874H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/8811-26384,9003H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/S06-848-A-22162-3377H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/9981-7396,13328H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/8811-28292,19773H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/s06-4441-2138-28904H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/S04-8172-43000-34101H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/s06-870-A1-23387-4365H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/S04-6577-25327-6843H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/s06-9179-a-11182-16963H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/s05-10520-11020-8395H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/4816-4772,4119H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/6501-1H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/S05-1575-C7-26205-27089H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/s06-8072-9131-7262H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/S05-1147-3140-6470H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/9981-9613,9562H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/s06-4352-6022-11380H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/s06-9179-a-21098-6878H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/S06-246B-21928-7450H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/S04-3584-18449-22489H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/s06-2790-7428-9129H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/S05-1147-7500-6033H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/8701-D-54400-19049H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/s06-9179-a-14757-22539H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/S04-6274-C16-31716-29992H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/S04-6274-C16-40313-32658H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/S04-6577-15603-12089H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/6670-2966,7266H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/S06-848-A-21263-7749H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/S06-246B-16950-11262H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/S05-1575-C7-27568-30199H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/S04-6537-22267-7100H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/s06-870-A1-21141-6608H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/9981-9947,10020H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/S03-3203-15967-14736H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/s06-4441-21605-29672H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/S05-1530-1490-6375H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/s04-7735-28648-19280H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/S06-106-2374-2088H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/s06-2790-7655-11377H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/S04-7685-B4-27018-16301H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/S04-6537-21861-21344H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/S03-10748-20370-31618H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/S05-1530-2405-17319H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/s06-4352-15194-5778H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/s06-8341-60236-25872H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/S03-9040-8680-14270H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/S03-10748-39559-17402H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/2/4816-22281,2869H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/3/s04-11695-18841-29097H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/3/s06-560-10210-9566H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/3/s04-1169-8165-29277H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/3/s04-1770-17295-20464H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/3/s05-555-17362-15522H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/3/s04-1169-16052-10969H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/3/s05-32558-8227H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/3/s06-8342-67888-15878H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/3/s05-1475-2602-3748H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/3/s03-6352-17414-12537H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/3/s04-7948A-13567-13772H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/3/s04-1772-21950-17946H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/3/9420-18634,14818H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/3/6321-13356,3173H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/3/S032199-B10-42262-26032H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/3/S04-8172-22230-24570H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/3/S03-9040-6434-15135H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/3/s03-6352-25331-27602H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/3/s05-28838-12568H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/3/s04-4066-5789-13367H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/3/S04-9969-20663-15146H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/3/s04-1770-3420-2894H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/3/s05-32135-27967H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/3/s06-7990-60502-20723H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/3/s06-870-A1-25026-17108H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/3/s04-7948A-17097-8087H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/3/S04-3481-8501-6440H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/3/s04-1770-2267-6780H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/3/s06-7990-63910-22668H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/3/s05-29502-19470H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/3/S06-7323-a5-41488-18047H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/3/s03-6352-17339-14353H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/3/s04-7948A-21007-8661H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/3/s04-7948A-16074-13527H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/3/s04-7735-28755-26387H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/3/s05-555-19084-20723H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/3/s04-1770-11201-4642H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/3/6321-8433,6225H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/3/S04-3481-27578-17769H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/3/s04-1772-17241-5296H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/3/s04-7735-19146-24779H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/3/s04-11695-19082-10774H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/3/s04-8539-24213-27383H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/3/s05-555-20636-6647H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/3/s05-555-20006-15153H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/3/s06-870-A1-54412-24065H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/3/9420-21263,19085H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/3/s06-7990-61014-21433H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/3/6321-9648,6912H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/3/s05-555-23824-14586H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/3/9420-9033,17419H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/3/s04-8539-18708-18744H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/3/9420-19277,10108H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/3/9420-29586,14674H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/3/9420-9791,15168H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/3/s06-5870-9821-28258H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/3/s06-560-20595-14830H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/3/s06-560-9115-10087H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/3/s05-35571-15429H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/3/6321-14512,8040H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/3/s06-560-6220-5526H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/3/s04-4066-5174-10777H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/3/s06-5870-20051-33187H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/3/6321-14557,2321H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/3/s06-8342-71049-14108H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/3/s04-7735-28789-13481H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/3/s04-1772-14730-5426H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/3/S05-1147-24682098H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/3/s04-11695-22912-29050H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/3/s05-555-18638-7616H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/3/s04-1770-21079-20831H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/3/s04-1772-11901-4400H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/3/s04-1770-18607-20060H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/3/s06-560-4976-4615H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/3/S04-9969-15667-16223H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/3/s04-8539-21142-27973H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/3/6321-13188,7594H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/3/9420-19564,24854H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/3/s04-8539-11138-22300H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/3/s04-7735-26037-31810H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/3/s04-8539-18293-26485H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/3/S032199-B10-38716-28995H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/3/s04-1770-6310-12042H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/1/S04-7685-B4-21755-31046H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/1/s04-4361-15918-34556H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/1/S03-3203-6750,9087H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/1/s04-6096-D5-35217-8279H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/1/9981-5013,5325H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/1/S04-6537-18646-21687H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/1/s04-4361-29952-6451H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/1/S06-106-5105-6251H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/1/S03-3203-9116-9572H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/1/s06-6874-14293-9019H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/1/S06-106-7873-5226H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/1/s04-4361-5855-29578H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/1/s04-4361-15445-36442H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/1/s04-1169-25434-31645H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/1/6670-6027,6543H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/1/9981-8805,2677H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/1/s04-4361-30376-6995H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/1/5578-5H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/1/9981-8999,2673H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/1/s06-6874-14448-15036H2.tif', '/home/diam/Desktop/HER2_data_categorical/Hamamatsu2/1/S05-1450-11168-20517H2.tif']\n"
     ]
    }
   ],
   "source": [
    "def get_data(folder):\n",
    "    X = []\n",
    "    y = []\n",
    "    filenames = []\n",
    "\n",
    "    for hclass in os.listdir(folder):\n",
    "        if not hclass.startswith('.'):\n",
    "            if hclass in [\"1\"]:\n",
    "                label = 1\n",
    "            else: #label must be 1 or 2\n",
    "                if hclass in [\"2\"]:\n",
    "                    label = 2\n",
    "                else:\n",
    "                    label = 3\n",
    "            for image_filename in os.listdir(folder + hclass):\n",
    "                filename = folder + hclass + '/' + image_filename\n",
    "                img_file = cv2.imread(folder + hclass + '/' + image_filename)\n",
    "                \n",
    "                if img_file is not None:\n",
    "                    img_file = scipy.misc.imresize(arr=img_file, size=(120, 160, 3))\n",
    "                    img_arr = np.asarray(img_file)\n",
    "                    X.append(img_arr)\n",
    "                    y.append(label)\n",
    "                    filenames.append(filename)\n",
    "\n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y)\n",
    "    z = np.asarray(filenames)\n",
    "    return X,y,filenames\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:20: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "241\n",
      "241\n",
      "241\n",
      "[[ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "X, y, z = get_data(BASE_PATH)\n",
    "\n",
    "\n",
    "#print(X)\n",
    "#print(y)\n",
    "#print(z)\n",
    "print(len(X))\n",
    "print(len(y))\n",
    "print(len(z))\n",
    "\n",
    "#INTEGER ENCODE\n",
    "#https://machinelearningmastery.com/how-to-one-hot-encode-sequence-data-in-python/\n",
    "encoder = LabelEncoder()\n",
    "y_cat = np_utils.to_categorical(encoder.fit_transform(y))\n",
    "print(y_cat)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#encoder = LabelEncoder()\n",
    "#encoder.fit(y)\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)\n",
    "\n",
    "#encoded_y_train = encoder.transform(y_train)\n",
    "#encoded_y_test = encoder.transform(y_test)\n",
    "\n",
    "#y_train = np_utils.to_categorical(encoded_y_train)\n",
    "#y_test = np_utils.to_categorical(encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Model with K-Fold X-Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "KFold(n_splits=2, random_state=5, shuffle=True)\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits = 2, random_state=5, shuffle=True)\n",
    "print(kf.get_n_splits(y_cat))\n",
    "print(kf)\n",
    "\n",
    "\n",
    "#for train_index, test_index in kf.split(y):\n",
    "#    X_train, X_test = X[train_index], X[test_index]\n",
    "#    print(train_index, test_index)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold #1\n",
      "Epoch 00068: early stopping\n",
      "Fold Score (accuracy): 0.768595041322\n",
      "[[ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]]\n",
      "[  1   3   4   6  10  12  15  17  19  21  23  24  25  26  28  34  36  37\n",
      "  39  40  42  43  45  46  48  49  50  51  53  54  55  56  57  59  60  61\n",
      "  62  63  66  71  74  75  77  79  84  87  88  89  90  93  95  96  97  98\n",
      " 101 102 104 114 115 117 119 122 123 127 130 134 136 138 139 140 145 148\n",
      " 149 151 153 154 156 160 161 162 163 165 169 170 171 172 173 176 177 178\n",
      " 180 182 184 185 186 187 192 196 197 198 200 202 207 209 211 213 214 215\n",
      " 216 217 220 221 223 224 225 226 232 234 238 239 240]\n",
      "fold #2\n",
      "Epoch 00067: early stopping\n",
      "Fold Score (accuracy): 0.708333333333\n",
      "[[ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]]\n",
      "[  0   2   5   7   8   9  11  13  14  16  18  20  22  27  29  30  31  32\n",
      "  33  35  38  41  44  47  52  58  64  65  67  68  69  70  72  73  76  78\n",
      "  80  81  82  83  85  86  91  92  94  99 100 103 105 106 107 108 109 110\n",
      " 111 112 113 116 118 120 121 124 125 126 128 129 131 132 133 135 137 141\n",
      " 142 143 144 146 147 150 152 155 157 158 159 164 166 167 168 174 175 179\n",
      " 181 183 188 189 190 191 193 194 195 199 201 203 204 205 206 208 210 212\n",
      " 218 219 222 227 228 229 230 231 233 235 236 237]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "oos_y = []\n",
    "oos_pred = []\n",
    "fold = 0\n",
    "\n",
    "\n",
    "for train, test in kf.split(y_cat):\n",
    "    fold+=1\n",
    "    print(\"fold #{}\".format(fold))\n",
    "        \n",
    "    X_train = X[train]\n",
    "    y_train = y_cat[train]\n",
    "    #z_train = z[train]\n",
    "    X_test = X[test]\n",
    "    y_test = y_cat[test]\n",
    "    #z_test = z[test]\n",
    "    \n",
    "    #encoder = LabelEncoder()\n",
    "    #encoder.fit(y_test)\n",
    "    #y_train = np_utils.to_categorical(encoder.transform(y_train))\n",
    "    #y_test = np_utils.to_categorical(encoder.transform(y_test))\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Lambda(lambda x: x * 1./255., input_shape=(120, 160, 3), output_shape=(120, 160, 3)))\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=(120, 160, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.7))\n",
    "    model.add(Dense(3))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                optimizer='rmsprop',\n",
    "                metrics=['accuracy'])\n",
    "    \n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=25, verbose=1, mode='auto')\n",
    "    \n",
    "    model.fit(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            validation_data=(X_test,y_test),\n",
    "            callbacks=[monitor],\n",
    "            shuffle=True,\n",
    "            batch_size=batch_size,\n",
    "            verbose=0,\n",
    "            epochs=1000)\n",
    "        \n",
    "    pred = model.predict(X_test)\n",
    "        \n",
    "    oos_y.append(y_test)\n",
    "    pred = np.argmax(pred,axis=1)\n",
    "    oos_pred.append(pred)\n",
    "    \n",
    "        #measure the fold's accuracy\n",
    "    y_compare = np.argmax(y_test,axis=1) #for accuracy calculation\n",
    "    score = metrics.accuracy_score(y_compare, pred)\n",
    "    print(\"Fold Score (accuracy): {}\".format(score))\n",
    "    print(y_test)\n",
    "    print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
